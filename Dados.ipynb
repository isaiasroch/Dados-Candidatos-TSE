{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bem_candidato_2024_BRASIL exportado para db/silver/bem_candidato_2024_BRASIL.parquet.\n",
      "consulta_cand_2024_BRASIL exportado para db/silver/consulta_cand_2024_BRASIL.parquet.\n",
      "consulta_cand_complementar_2024_BRASIL exportado para db/silver/consulta_cand_complementar_2024_BRASIL.parquet.\n",
      "consulta_coligacao_2024_BRASIL exportado para db/silver/consulta_coligacao_2024_BRASIL.parquet.\n",
      "consulta_vagas_2024_BRASIL exportado para db/silver/consulta_vagas_2024_BRASIL.parquet.\n",
      "motivo_cassacao_2024_BRASIL exportado para db/silver/motivo_cassacao_2024_BRASIL.parquet.\n",
      "rede_social_candidato_2024_BRASIL exportado para db/silver/rede_social_candidato_2024_BRASIL.parquet.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Diretórios onde os arquivos CSV estão localizados\n",
    "bronze_directory = \"db/bronze/\"\n",
    "silver_directory = \"db/silver/\"\n",
    "\n",
    "# Cria os diretórios para as camadas bronze e prata (se não existirem)\n",
    "os.makedirs(bronze_directory, exist_ok=True)\n",
    "os.makedirs(silver_directory, exist_ok=True)\n",
    "\n",
    "\n",
    "# Lista todos os arquivos no diretório bronze\n",
    "files = os.listdir(bronze_directory)\n",
    "\n",
    "# Itera sobre os arquivos e lê cada CSV\n",
    "for file in files:\n",
    "    if file.endswith(\".csv\"):\n",
    "        # Gera o nome do DataFrame a partir do nome do arquivo (sem extensão)\n",
    "        df_name = file.split(\".\")[0]\n",
    "        \n",
    "        # Lê o CSV e armazena no DataFrame correspondente\n",
    "        df = pd.read_csv(os.path.join(bronze_directory, file), encoding='latin1', sep=';', on_bad_lines='skip')\n",
    "        \n",
    "        # Define o caminho de saída para o arquivo Parquet na camada prata\n",
    "        parquet_path = os.path.join(silver_directory, f\"{df_name}.parquet\")\n",
    "        \n",
    "        # Exporta o DataFrame para Parquet\n",
    "        df.to_parquet(parquet_path, index=False)\n",
    "        \n",
    "        # Exibe uma mensagem confirmando que o arquivo foi exportado\n",
    "        print(f\"{df_name} exportado para {parquet_path}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bem_candidato_2024_BRASIL exportado para db/silver/bem_candidato_2024_BRASIL.parquet.\n",
      "bem_candidato_2024_BRASIL carregado no PostgreSQL na tabela bem_candidato_2024_brasil.\n",
      "consulta_cand_2024_BRASIL exportado para db/silver/consulta_cand_2024_BRASIL.parquet.\n",
      "consulta_cand_2024_BRASIL carregado no PostgreSQL na tabela consulta_cand_2024_brasil.\n",
      "consulta_cand_complementar_2024_BRASIL exportado para db/silver/consulta_cand_complementar_2024_BRASIL.parquet.\n",
      "consulta_cand_complementar_2024_BRASIL carregado no PostgreSQL na tabela consulta_cand_complementar_2024_brasil.\n",
      "consulta_coligacao_2024_BRASIL exportado para db/silver/consulta_coligacao_2024_BRASIL.parquet.\n",
      "consulta_coligacao_2024_BRASIL carregado no PostgreSQL na tabela consulta_coligacao_2024_brasil.\n",
      "consulta_vagas_2024_BRASIL exportado para db/silver/consulta_vagas_2024_BRASIL.parquet.\n",
      "consulta_vagas_2024_BRASIL carregado no PostgreSQL na tabela consulta_vagas_2024_brasil.\n",
      "motivo_cassacao_2024_BRASIL exportado para db/silver/motivo_cassacao_2024_BRASIL.parquet.\n",
      "motivo_cassacao_2024_BRASIL carregado no PostgreSQL na tabela motivo_cassacao_2024_brasil.\n",
      "rede_social_candidato_2024_BRASIL exportado para db/silver/rede_social_candidato_2024_BRASIL.parquet.\n",
      "rede_social_candidato_2024_BRASIL carregado no PostgreSQL na tabela rede_social_candidato_2024_brasil.\n"
     ]
    }
   ],
   "source": [
    "# csv to db\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Conectando ao PostgreSQL\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    database=\"postgres\",\n",
    "    user=\"postgres\",\n",
    "    password=\"31415926\"\n",
    ")\n",
    "\n",
    "# Diretório onde os arquivos CSV estão localizados\n",
    "bronze_directory = \"db/bronze/\"\n",
    "silver_directory = \"db/silver/\"\n",
    "\n",
    "# Cria o diretório para a camada prata (se não existir)\n",
    "os.makedirs(silver_directory, exist_ok=True)\n",
    "\n",
    "# Lista todos os arquivos no diretório bronze\n",
    "files = os.listdir(bronze_directory)\n",
    "\n",
    "# Define o engine para SQLAlchemy usando psycopg2\n",
    "engine = create_engine('postgresql+psycopg2://postgres:31415926@localhost/postgres')\n",
    "\n",
    "# Itera sobre os arquivos e lê cada CSV\n",
    "for file in files:\n",
    "    if file.endswith(\".csv\"):\n",
    "        # Gera o nome do DataFrame a partir do nome do arquivo (sem extensão)\n",
    "        df_name = file.split(\".\")[0]\n",
    "        \n",
    "        # Lê o CSV e armazena no DataFrame correspondente\n",
    "        df = pd.read_csv(os.path.join(bronze_directory, file), encoding='latin1', sep=';', on_bad_lines='skip')\n",
    "        \n",
    "        # Define o caminho de saída para o arquivo Parquet na camada prata\n",
    "        parquet_path = os.path.join(silver_directory, f\"{df_name}.parquet\")\n",
    "        \n",
    "        # Exporta o DataFrame para Parquet\n",
    "        df.to_parquet(parquet_path, index=False)\n",
    "        \n",
    "        # Exibe uma mensagem confirmando que o arquivo foi exportado\n",
    "        print(f\"{df_name} exportado para {parquet_path}.\")\n",
    "        \n",
    "        # Escreve o DataFrame no PostgreSQL usando chunksize para evitar MemoryError\n",
    "        table_name = df_name.lower()  # Converte o nome do DataFrame para minúsculas para usar como nome da tabela\n",
    "        df.to_sql(table_name, con=engine, if_exists='replace', index=False, chunksize=10000)\n",
    "        \n",
    "        # Exibe uma mensagem confirmando que o DataFrame foi escrito no PostgreSQL\n",
    "        print(f\"{df_name} carregado no PostgreSQL na tabela {table_name}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cand = pd.read_parquet(\"db/silver/consulta_cand_2024_BRASIL.parquet\")\n",
    "\n",
    "cand_ma = cand[cand['SG_UF'] == \"MA\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
